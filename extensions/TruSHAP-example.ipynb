{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TruSHAP\n",
    "\n",
    "Add your model to a TruEra deployment with only 2! code changes to your notebooks that already use SHAP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1: Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from truera.client.experimental.trushap import trushap as shap\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import pandas as pd\n",
    "import xgboost\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = shap.datasets.adult()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                    test_size = 0.3,\n",
    "                                    random_state = 123)\n",
    "                                    \n",
    "model = xgboost.XGBRegressor().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0: Get Shapley Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connection details\n",
    "CONNECTION_STRING = \"https://app.truera.net/\"\n",
    "TOKEN = \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just add connection string and token (optional)\n",
    "explainer = shap.Explainer(model, connection_string = CONNECTION_STRING, token = TOKEN)\n",
    "\n",
    "shap_values = explainer(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Use existing SHAP Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2: Explore your new project in the TruEra Web App\n",
    "\n",
    "Visit your TruEra application and explore to better understand the performance of your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3: Be intentional about naming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add naming\n",
    "explainer = shap.Explainer(model,\n",
    "                            connection_string = CONNECTION_STRING,\n",
    "                            token = TOKEN,\n",
    "                            project = \"Adult Census Example\",\n",
    "                            data_collection_name = \"Adult Census Data Collection\",\n",
    "                            model_name = \"XGBRegressor V1\"\n",
    "                            )\n",
    "\n",
    "shap_values = explainer(X, data_split_name = \"all\", split_type = \"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4: Add label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = pd.concat([X, pd.DataFrame(y.astype(float), columns=[\"label\"])], axis = 1)\n",
    "\n",
    "shap_values = explainer(data_all, data_split_name = \"all_w_labels\",\n",
    "    pre_data_col_names = list(X.columns),\n",
    "    label_col_names=[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6: Compare models against each other and across multiple splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add multiple models\n",
    "xgb_model = xgboost.XGBRegressor(max_depth = 6, min_child_weight = 2).fit(X_train, y_train)\n",
    "\n",
    "explainer_xgb = shap.Explainer(xgb_model,\n",
    "                            connection_string = CONNECTION_STRING,\n",
    "                            token = TOKEN,\n",
    "                            project = \"Adult Census Model Comparison 2\",\n",
    "                            data_collection_name = \"Adult Census Data Collection\",\n",
    "                            model_name = \"XGBRegressor\",\n",
    "                            train_parameters = {\"max_depth\":6,\n",
    "                                                \"min_child_weight\":2}\n",
    "                            )\n",
    "\n",
    "train_data = pd.concat([X_train, pd.DataFrame(y_train.astype(float), columns=[\"label\"])], axis = 1)\n",
    "test_data = pd.concat([X_test, pd.DataFrame(y_test.astype(float), columns=[\"label\"])], axis = 1)\n",
    "\n",
    "shap_values_xgb_train = explainer_xgb(train_data,\n",
    "    data_split_name = \"train\",\n",
    "    pre_data_col_names = list(X_train.columns),\n",
    "    label_col_names=[\"label\"])\n",
    "shap_values_xgb_test = explainer_xgb(test_data,\n",
    "    data_split_name = \"test\",\n",
    "    pre_data_col_names = list(X_test.columns),\n",
    "    label_col_names=[\"label\"])\n",
    "\n",
    "tree_model = DecisionTreeRegressor(max_depth=6).fit(X_train, y_train)\n",
    "\n",
    "explainer_tree = shap.Explainer(tree_model,\n",
    "                            connection_string = CONNECTION_STRING,\n",
    "                            token = TOKEN,\n",
    "                            project = \"Adult Census Model Comparison\",\n",
    "                            data_collection_name = \"Adult Census Data Collection\",\n",
    "                            model_name = \"Decision Tree Regression\",\n",
    "                            train_parameters = {\"max_depth\": 6}\n",
    "                            )\n",
    "\n",
    "shap_values_tree_train = explainer_tree(train_data,\n",
    "    data_split_name = \"train\",\n",
    "    pre_data_col_names = list(X_train.columns),\n",
    "    label_col_names=[\"label\"])\n",
    "shap_values_tree_test = explainer_tree(test_data,\n",
    "    data_split_name = \"test\",\n",
    "    pre_data_col_names = list(X_test.columns),\n",
    "    label_col_names=[\"label\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0: Unlock More Capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.0: Using the TruEra Explainer - Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru = explainer.get_truera_workspace()\n",
    "\n",
    "tru_explainer = tru.get_explainer('all_w_labels')\n",
    "\n",
    "tru_explainer.get_global_feature_importances()\n",
    "\n",
    "tru_explainer.plot_isp('Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Using the TruEra Explainer - Find High Error Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_explainer.suggest_high_error_segments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2: Get Serious with the Test Harness\n",
    "\n",
    "Establish performance, fairness, feature importance and stability tests using the TruEra Test Harness.\n",
    "\n",
    "1. Performance tests warn and/or fail if any of a number of metrics (accuracy, precision, AUC, etc) reaches a specified threshold.\n",
    "\n",
    "2. Fairness tests establish criteria to compare a protected segment against the rest of the population.\n",
    "\n",
    "3. Feature Importance tests ensure there are not too many unimportant features in the model.\n",
    "\n",
    "4. Stability ensures that the behavior of the model is similar across two distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set environment to the remote project, set context in remote\n",
    "tru.set_project(\"Adult Census Model Comparison\")\n",
    "tru.set_data_collection(\"Adult Census Data Collection\")\n",
    "tru.set_data_split(\"train\")\n",
    "\n",
    "#set up protected segment for fairness test\n",
    "#tru.add_segment_group(name = \"Gender\", segment_definitions = dict({\"Male\": 'Sex == 1', 'Female': 'Sex == 0'}) )\n",
    "tru.set_as_protected_segment(segment_group_name = \"Gender\", segment_name = \"Female\")\n",
    "\n",
    "#performance test\n",
    "for split_name in [\"train\", \"test\"]:\n",
    "    tru.tester.add_performance_test( test_name = \"Performance Test 1\",\n",
    "        data_split_names = [split_name],\n",
    "        fail_if_greater_than = 0.3,\n",
    "        metric = \"RMSE\",\n",
    "        overwrite = True)\n",
    "\n",
    "    #fairness test\n",
    "    tru.tester.add_fairness_test( test_name = \"Fairness Test 1\",\n",
    "    data_split_names = [split_name],\n",
    "    all_protected_segments=True,\n",
    "    metric = \"MEAN_SCORE_DIFFERENCE\",\n",
    "    fail_if_outside = [-0.1,0.1], warn_if_outside = [-0.05, 0.05],\n",
    "    overwrite = True)\n",
    "\n",
    "    #feature importance test\n",
    "    tru.tester.add_feature_importance_test(test_name = \"FI Test 1\",\n",
    "                                            data_split_names = [split_name],\n",
    "                                            min_importance_value= 0.02,\n",
    "                                            warn_if_greater_than = 0,\n",
    "                                            fail_if_greater_than = 5,\n",
    "                                            overwrite = True)\n",
    "\n",
    "#stability test\n",
    "tru.tester.add_stability_test(test_name = \"Stability Test 1\",\n",
    "                                base_data_split_name=\"train\",\n",
    "                                comparison_data_split_names=[\"test\"],\n",
    "                                metric=\"DIFFERENCE_OF_MEAN\",\n",
    "                                warn_if_greater_than = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3: Check the Model Leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.tester.get_model_leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Explore the Test Results Further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.set_model(\"XGBRegressor\")\n",
    "tru.tester.get_model_test_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Explore failed tests using your TruEra Web App (Explore in the UI)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('trushap_dogfood')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7aa97c1df1c6a49f2b25a8044eda10fdf466ae354d7c43bfcb1fcdf3516b8a53"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
